# Using package 'allHiC' in assembling nanopore assembly with HiC information
Nan Hu / Oct. 18, 2020

---

## Basical introduction
This pipeline is designed for using HiC sequencing data with nanopore assemblies attempting fetching relatively chromosomal level assemblies. Most of ideas refer to [ALLHiC Github](https://github.com/tangerzhang/ALLHiC/wiki).

The entire workflow for nanopore assembly, NGS data polishment, and HiC chromatin signal incorpration are shown below:
![Main Workflow](https://github.com/gudusanjiao/HiCassembly/blob/main/miscellaneous/Workflow.png "Workflow")
Steps below are a pipeline started from raw nanopore aseembly to reach chromosomal level assembly (Yellow box above). It works fine with *Salix nigra* now. There have been issues with *Salix exigua* which we are still working on it. 

To prepare the softwares in this pipeline, you need to install [ALLHiC](https://github.com/tangerzhang/ALLHiC/wiki), [samtools](http://samtools.sourceforge.net/), [bedtools](https://bedtools.readthedocs.io/en/latest/), [bwa](http://bio-bwa.sourceforge.net/), and [matplotlib](https://matplotlib.org/users/installing.html).

## Step 1: Index raw nanopore assembly
This step take raw nanopore aseembly fasta file as input to create index file for both alignment and BAM file operations.
> When we call 'raw assembly' here, we refer to assembly using nanopore reads assembled by chosen aseemblers, and then polished by NextPolish using NGS read. Noted here, the 'raw assembly' is not 'raw', it is after 4 rounds of polishing. This term will be use for all following steps unless special mentions.

If your genome assembly is already indexed previously due to other analyzing process, you may skip this step.

`SN_flye1_nextpolish4.fasta` file is the raw assembly of *Salix nigra* stored under `./ref/`
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SN_allHiC_index
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/01/$JOB_NAME.o$JOB_ID
#$ -e log/01/$JOB_NAME.e$JOB_ID
#$ -pe sm 1
#$ -P quanah

bwa index -a bwtsw ./ref/SN_flye1_nextpolish4.fasta  
samtools faidx ./ref/SN_flye1_nextpolish4.fasta
```
Output files are `.bwt`, `.pac`, `.ann`, `.amb` files.

## Step 2: Align HiC reads to raw nanopore assembly
HiC reads are generated by sequencing DNA segments that potentially binds by chromatins. This step we will map all the HiC reads to raw assembly. Since we have multiple HiC returned file, we need to do mapping for each file separately.

`./HiC` is where we stored our HiC reads.
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SN_allHiC_rawAlign
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/02/$JOB_NAME.o$JOB_ID
#$ -e log/02/$JOB_NAME.e$JOB_ID
#$ -pe sm 36
#$ -P quanah

bwa aln -t 36 ./ref/SN_flye1_nextpolish4.fasta ./HiC/SN527M_39.77G/HIC127_L2_1003876.R1.fastq.gz > SN_HiC_s1_R1.sai  
bwa aln -t 36 ./ref/SN_flye1_nextpolish4.fasta ./HiC/SN527M_39.77G/HIC127_L2_1003876.R2.fastq.gz > SN_HiC_s1_R2.sai
bwa sampe ./ref/SN_flye1_nextpolish4.fasta \ 
          SN_HiC_s1_R1.sai \ 
          SN_HiC_s1_R2.sai \ 
          ./HiC/SN527M_39.77G/HIC127_L2_1003876.R1.fastq.gz \
          ./HiC/SN527M_39.77G/HIC127_L2_1003876.R2.fastq.gz > SN_HiC_s1.sam

bwa aln -t 36 ./ref/SN_flye1_nextpolish4.fasta ./HiC/SN527M_5.96G/HIC127_L2_1003876.R1.fastq.gz > SN_HiC_s2_R1.sai
bwa aln -t 36 ./ref/SN_flye1_nextpolish4.fasta ./HiC/SN527M_5.96G/HIC127_L2_1003876.R2.fastq.gz > SN_HiC_s2_R2.sai
bwa sampe ./ref/SN_flye1_nextpolish4.fasta \ 
          SN_HiC_s2_R1.sai SN_HiC_s2_R2.sai \ 
          ./HiC/SN527M_5.96G/HIC127_L2_1003876.R1.fastq.gz \ 
          ./HiC/SN527M_5.96G/HIC127_L2_1003876.R2.fastq.gz > SN_HiC_s2.sam
```
This step takes several hours to finish. Output files are pair-end mapping `.sai` files and aligned read file `.sam`.

## Step 3: Filter alignment
This step will do 1) pre-filter reads without restriction enzyme sites 2) removing low-quality mapping hits 3) converting `.sam` file to `.bam` file.

`PreprocessSAMs.pl` requires a restriction enzyme name used during genome digestion before HiC sequencing. It is either MboI (N|GATC / CTAG|N) or HindIII (A|AGCTT / TTCGA|A). Before processing this step, you need to check the enzyme using for digesting genome by asking the sequencing company. `PreprocessSAMs.pl` will produce `.pos_of_GATC.txt`, `.near_GATC.500.bed`, `.REduced.bam`, `.REduced.paired_only.bam`, and `.REduced.paired_only.flagstat` files. Use the name of `.REduced.paired_only.bam` as the input for `filterBAM_forHiC.pl`.

```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SN_allHiC_filter
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/03/$JOB_NAME.o$JOB_ID
#$ -e log/03/$JOB_NAME.e$JOB_ID
#$ -pe sm 36
#$ -P quanah

PreprocessSAMs.pl SN_HiC_s1.sam SN_flye1_nextpolish4.fasta MBOI
filterBAM_forHiC.pl SN_HiC_s1.REduced.paired_only.bam SN_HiC_s1_clean.sam
samtools view -bt ./ref/SN_flye1_nextpolish4.fasta.fai SN_HiC_s1_clean.sam > SN_HiC_s1_clean.bam

PreprocessSAMs.pl SN_HiC_s2.sam SN_flye1_nextpolish4.fasta MBOI
filterBAM_forHiC.pl SN_HiC_s2.REduced.paired_only.bam SN_HiC_s2_clean.sam
samtools view -bt /ref/SN_flye1_nextpolish4.fasta.fai SN_HiC_s2_clean.sam > SN_HiC_s2_clean.bam
```
Output of this step are `_clean.bam` files.

## Step 4: Merge BAM files
This step merge filtered results from each read files into a single one.
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SN_allHiC_mergeBAM
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/04/$JOB_NAME.o$JOB_ID
#$ -e log/04/$JOB_NAME.e$JOB_ID
#$ -pe sm 6
#$ -P quanah

samtools merge SN_HiC.bam SN_HiC_s1_clean.bam SN_HiC_s2_clean.bam
```
Output of this step is a single `.bam` file. I named it `SN_HiC.bam` here.

## Step 5: Prune allelic links and weak signals (Optional. Only for polyploids)
**Skip step 5 and step 7 if you are working on diploid individuals.**
This is only for dealing with polyploids in assembly. Before we go to further steps, we need to prune the HiC signals generated by polyploidy level. There are two ways to mark the paralogs due to genome duplication (See [identify allelic contigs using annotation](https://github.com/tangerzhang/ALLHiC/wiki/ALLHiC:-identify-allelic-contigs) and [identify allelic contigs without annotation target genome](https://github.com/tangerzhang/ALLHiC/issues/16)). We used the second approach since we do not have the annotation for our target species but we have one for closed related species *Salix purpurea*. We used *Salix exigua* file as an example here since in our previous estimation of genome size, the male of our sampling in *Salix exigua* exhibits evidences for being a tetraploid.

We need to install gmap software for this step. Details are in [GMAP manual](http://research-pub.gene.com/gmap/).

Making GMAP database:
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N gmap_Spur2SE
#$ -q omni
#$ -pe sm 18
#$ -P quanah

gmap_build -D . -d DB ./ref/SE.finalpolish.fasta
gmap -D . -d DB -t 18 -f 2 -n 4 ./ref/Spurpurea_519_v5.1.cds.fa.gz > Spur2SE_gmap.gff3
```
Building gmap betweem *S. exigua* and *S. purpurea*:
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N gmap_Spur2SE_gff
#$ -q omni
#$ -pe sm 18
#$ -P quanah

gmap -D . -d DB -t 18 -f 2 -n 4 ./ref/Spurpurea_519_v5.1.cds.fa > Spur2SE_gmap.gff3
```
Generate allelic table:
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N alletic_table
#$ -q omni
#$ -pe sm 18
#$ -P quanah

mv Spur2SE_gmap.gff3 gmap.gff3
perl ~/software/ALLHiC/scripts/gmap2AlleleTable.pl gmap.gff3
```
perl script used here is located at `<path of ALLHiC>/scripts/`.

After fetching a `Allele.ctg.table` file from above processes, we can use `ALLHiC_prune` to remove redundant signals for our HiC assembly.
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SE_allHiC_prune
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/05/$JOB_NAME.o$JOB_ID
#$ -e log/05/$JOB_NAME.e$JOB_ID
#$ -pe sm 36
#$ -P quanah

module load gnu/5.4.0

ALLHiC_prune -i ./gmap/Allele.ctg.table -b SE_HiC.bam -r ./ref/SE.finalpolish.fasta
```
(In progress)

## Step 6: Partition: Assign contigs into a pre-defined number of groups
This step runs for assign contigs into groups based on HiC signals. Parameter `-e` refers to restriction enzyme sites (See step 4). Parameter `-k` refers to pre-defined number of groups. In our case, as we know the linkage group number is 19 for willows, `-k` should be 19. However, I was too ambious to expect the software would discriminate X and Y chromosomes for me. Thus, I put 20 for this parameter.
```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SN_allHiC_partition
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/06/$JOB_NAME.o$JOB_ID
#$ -e log/06/$JOB_NAME.e$JOB_ID
#$ -pe sm 36
#$ -P quanah

module load gnu/5.4.0

ALLHiC_partition -b SN_HiC.bam -r ./ref/SN_flye1_nextpolish4.fasta -e GATC -k 20
```
Output of this step are list of `.group` files. They are contigs included in each putative linkage groups.

## Step 7: Rescue: Assign unplaced contigs into partitioned clusters (Optional. Only for ployploids)
Using *Salix exigua* file as an example for the same reason as step 5.

```bash
#!/bin/sh
#$ -V
#$ -cwd
#$ -S /bin/bash
#$ -N SE_allHiC_rescue
#$ -q omni
#$ -l h_vmem=5.3G
#$ -o log/07/$JOB_NAME.o$JOB_ID
#$ -e log/07/$JOB_NAME.e$JOB_ID
#$ -pe sm 36
#$ -P quanah

module load gnu/5.4.0

ALLHiC_rescue -r ./ref/SE.finalpolish.fasta -b SE_HiC.bam -c prunning.clusters.txt -i prunning.counts_GATC.txt
```
(In progress)

## Step 8: Extract grouping inforation
(Occupied needs updating)

## Step 9: Optimize directions of contigs
(Occupied needs updating)

## Step 10: Build FASTA file
(Occupied needs updating)

## Step 11: Plot chromatin contacting map
(Occupied needs updating)
